{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About me and this site","text":"<p>Starting this site as a scratch pad on my learnings in programming, machine learning and AI. I expect most of the writings here to be of little value to anyone, at best hoping that a few lines here and there may end up being original and of some consequence. </p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/","title":"1. Introduction to Generative AI","text":""},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#goals-of-a-generative-model","title":"Goals of a generative model","text":"<p>The primary objective of a generative model (with parameters \\(\\theta\\)) is to approximate via \\(P_\\theta(\\mathbf{x})\\) the data distribution \\(P_{data}(\\mathbf{x})\\) given a sufficiently large set of training samples from an independent and identically distributed training distribution \\(P_{train}(\\mathbf{x})\\). </p> <p>However an effective generative model would also be able to capture patterns, dependencies and features present in the data. And there is a trade-off between maximising likelihood (overfitting to \\(P_{train}(\\mathbf{x})\\)) vs extracting the latent space structure so that features can be learnt and modelled.</p> <p>Along with these primary objectives, a good generative model should also support efficient sampling from \\(P_\\theta(\\mathbf{x})\\) laying emphasis on diversity and fidelity of generated samples.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#model-parameter-estimation","title":"Model parameter estimation","text":"<p>Most machine learning techniques have to make a choice on how they estimate parameters of the model, generally based on the phenomenon they try to model. </p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#maximum-a-posteriori-map","title":"Maximum a posteriori (MAP)","text":"<p>If there exists some kind of a-priori knowledge of the phenomenon (e.g. physical laws or financial laws), then these could be used as a start to the modelling process. Further fine-tuning of the parameters are then made based on the training samples. MAP incorporates prior knowledge through a prior distribution \\(P(\\theta)\\). It finds the parameter that maximises the posterior distribution \\(P(\\theta | \\mathbf{x})\\). Using Bayes theorem, the posterior distribution is given by</p> \\[ P(\\theta | \\mathbf{x}) = \\frac{P(\\mathbf{x} | \\theta) P(\\theta)}{P(\\mathbf{x})} \\] <p>Since \\(P(\\mathbf{x})\\) does not depend on \\(\\theta\\), it can be ignored during optimisation. Thus the MAP estimate \\(\\hat{\\theta}_{\\text{MAP}}\\)\u200b is the parameter that maximises the posterior (log for simplifying the computations)</p> \\[ \\hat{\\theta}_{\\text{MAP}} = \\arg \\max_{\\theta} \\big( \\log P(\\mathbf{x} | \\theta) + \\log P(\\theta) \\big) \\]"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#maximum-likelihood-estimation-mle","title":"Maximum  likelihood estimation (MLE)","text":"<p>In generative models typically, there is no prior distribution available to begin the parameter optimisation. Therefore frequentist methods of estimation like maximum likelihood are employed. The objective here reduces to finding the parameters \\(\\hat{\\theta}_{\\text{MLE}}\\) that maximises the likelihood of the observed data \\(\\mathbf{x}\\). </p> \\[ \\hat{\\theta}_{\\text{MLE}} = \\arg \\max_{\\theta} \\big(\\log P(\\mathbf{x} | \\theta) \\big) \\] Frequentist statistics <p>Frequentist statistics is a framework for statistical inference based on the idea that probabilities are long-run frequencies of events. Frequentist  methods do not incorporate prior information about the parameters. Instead, they rely solely on the observed data to make inferences.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#analysing-probability-distributions","title":"Analysing probability distributions","text":"<p>Since we aim to model probability distributions, we need some means of analysing different distributions as well as metrics for comparing distributions. Shannon's information theory gives us a good basis for analysing probability distributions in terms of their information content and compressibility.</p> Shannon's Information Theory <p>In A Mathematical Theory of Communication, Shannon laid the groundwork for  information theory by introducing concepts like entropy, channel capacity, and coding theory. His work showed how information can be transmitted reliably over noisy channels and how data can be compressed efficiently.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#entropy-of-a-distribution","title":"Entropy of a distribution","text":"<p>The idea of entropy was introduced to understand the information content of a distribution. Information theory defines information in terms of the uncertainty or surprise associated with random variable. Entropy quantifies the expected amount of \"surprise\" in observing outcomes from a distribution. For a random variable \\(\\mathbf{x}\\) with possible outcomes \\(x\\) the entropy is given by</p> \\[ H(\\mathbf{x}) = -\\sum_x P(x) \\log P(x) \\] <p>A high entropy indicates a distribution with high uncertainty (e.g., a uniform distribution where all outcomes are equally likely), while a low entropy indicates a more predictable distribution (e.g., a delta distribution concentrated on a single outcome). The Shannon entropy, when calculated with a base-2 logarithm, measures information in bits, providing a direct interpretation of information content that is both intuitive and mathematically optimal for digital communication. It effectively gives us the minimum bits needed to optimally compress a random variable given its probability distribution.</p> <p>In generative AI, the concept of entropy when extended to cross-entropy between two probabilities and its associated distance metrics gives us the necessary tools to compare probability distributions.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#cross-entropy-of-two-distributions","title":"Cross entropy of two distributions","text":"<p>Cross-entropy is a measure of the difference between two probability distributions and is widely used as a loss function in machine learning (ML) models. When used for example in generative AI, cross-entropy quantifies the \"distance\" between the true distribution (the actual samples from \\(P_{data}\\)) and the model distribution (generated from \\(P_\\theta\\)). The lower the cross-entropy, the closer the model's generation mimics the data distribution. </p> <p>For discrete probability distributions \\(P\\) and \\(Q\\) over the same set of events, the cross-entropy \\(H(P,Q)\\) is given by </p> \\[ H(P, Q) = -\\sum_{x}P(x)\\log Q(x) \\] <p>Cross-entropy can be decomposed into two parts: the entropy of the true distribution and an additional term known as the KL divergence (or relative entropy) between the true distribution and the model distribution. This decomposition highlights how cross-entropy combines information from the true distribution\u2019s inherent uncertainty and the \"extra cost\" of using the model distribution </p> \\[ H(P, Q) = H(P) + D_{KL}(P||Q) \\] <p>Intuitively, in Information Theory parlance, the cross entropy decomposition can be thought of as representing the number of bits needed to compress the true distribution optimally and the KL divergence being the additional bits needed if information is compressed according to the model distribution.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#distance-measure-kl-divergence","title":"Distance measure (KL divergence)","text":"<p>This leads us to a possible distance measure between distributions \\(P\\) and \\(Q\\) when using Shannon's entropy and cross-entropy which is the Kullback-Leibler (KL) divergence given by</p> \\[ D_{KL}\u200b(P||Q)=\\sum_x\u200bP(x)log\\frac{P(x)}{Q(x)}\u200b \\] <p>The divergence \\(D_{KL}(P||Q) \\ge 0\\) for all \\(P\\), \\(Q\\) with equality if and only if \\(P = Q\\) and therefore it can be used as a reasonable measure to compare distributions although it is not a true metric.</p> Metric space theory and true distance metrics <p>The notion of a metric comes from metric space theory in mathematics, particularly within topology and geometry. The metric concept provides a formal way to measure \"distance\" between elements in a space. A metric on  a set \\(X\\) is a function \\(d: X \\times X \\rightarrow \\mathbb{R}\\) that  satisfies the following properties:</p> <ol> <li>Non-negativity: \\(d(x, y) \\geq 0\\) </li> <li>Identity of indiscernibles: \\(d(x, y) = 0\\) if and only if \\(x=y\\)</li> <li>Symmetry: \\(d(x,y)=d(y,x)\\) </li> <li>Triangle inequality: \\(d(x, z) \\leq d(x, y) + d(y, z)\\)</li> </ol> <p>The KL divergence is not a true distance metric because it is not symmetric and it does not obey the triangle inequality. However there are other measures of distance (Wasserstein, Jensen-Shannon etc.) based on other \"divergences\" and \"entropy\" definitions (generalised as f-divergences), some of which are true metrics.</p>"},{"location":"Generative%20AI/1.%20Introduction%20to%20Generative%20AI/#kl-divergence-in-generative-modelling","title":"KL divergence in generative modelling","text":"<p>For a generative model \\(P_\\theta(\\mathbf{x})\\) with the corresponding data distribution \\(P_{data}(\\mathbf{x})\\), the KL divergence can be stated as</p> \\[ \\begin{split} D_{KL}\u200b(P_{data}||P_\\theta) &amp;= \\mathbb{E}_{\\mathbf{x}\\sim P_{data}} \u200b\\left[\\log \\left( \\frac{P_{data}(\\mathbf{x})}{P_\\theta(\\mathbf{x})} \\right) \\right] \\\\ &amp;= \\mathbb{E}_{\\mathbf{x}\\sim P_{data}} \u200b\\left[\\log P_{data}(\\mathbf{x}) \\right] - \\mathbb{E}_{\\mathbf{x}\\sim P_{data}} \u200b\\left[\\log {P_\\theta(\\mathbf{x})} \\right] \\end{split}\u200b \\] <p>And since the first terms does not depend on \\(P_\\theta\\), minimising KL divergence in generative modelling reduces to maximising the expected log-likelihood (MLE)</p> \\[ \\arg \\min_{\\theta} D_{KL}\u200b(P_{data}||P_\\theta) = \\arg \\max_{\\theta}\\mathbb{E}_{\\mathbf{x}\\sim P_{data}} \u200b\\left[\\log {P_\\theta(\\mathbf{x})} \\right] \\] <p>This also shows us that although we can compare models \\(P_{\\theta_1}\\) and \\(P_{\\theta_2}\\) in which of them more closely models the true data distribution \\(P_{data}\\), we cannot know how close we are to the \\(P_{data}\\) itself with either of them.</p> <p>In practise we approximate the expected log-likelihood with the empirical log-likelihood over training samples \\(D\\). This follows from Monte Carlo estimation.</p> \\[ \\hat{\\theta}_{\\text{MLE}} = \\max_{\\theta} \\frac {1}{|D|}\\sum_{x \\in D}\\log P_\\theta(x) \\] Monte Carlo estimation <p>Monte Carlo Estimation is a method for approximating an unknown quantity, typically an expectation, integral, or sum, using random sampling. It is  particularly useful when direct analytical computation is intractable due to  high dimensionality or complexity.</p>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/","title":"2. Autoregressive models","text":""},{"location":"Generative%20AI/2.%20Autoregressive%20models/#introduction","title":"Introduction","text":"<p>Autoregressive models as the name implies, generates data by predicting each element sequentially based on the elements previously generated. They are naturally aligned to tasks involving sequential dependence like natural language, audio and time-series data. However, autoregressive models have also been successfully applied to image generation.</p> <ul> <li>GPT (Generative Pre-trained Transformer) is a language model that predicts the next word or token based on previously generated text.</li> <li>PixelCNN and PixelRNN generate images pixel by pixel, with each pixel depending on the pixels generated before it.</li> <li>WaveNet produces audio samples one at a time, with each sample conditioned on prior samples, making it suitable for realistic speech and audio synthesis.</li> </ul>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/#factorisation-of-a-probability-distribution","title":"Factorisation of a probability distribution","text":"<p>In the autoregressive approach we are either dealing with an ordered sequence (language) or unordered vector samples (images) and in general the data can be thought of as multi-dimensional vectors and their probability distributions are best represented as joint distributions over all these dimensions. A joint distribution over an n-dimensional vector can be stated accurately using the chain rule of probabilities as</p> \\[ p(x_1, x_2, \\dots, x_n) = p(x_n | x_{n-1}, \\dots, x_2, x_1) \\dots p(x_3 | x_2, x_1) \\cdot p(x_2 | x_1) \\cdot p(x_1) \\] <p>The principle behind autoregression is to compute this factorisation sequentially. For large dimensions this factorisation requires an exponentially large number of parameters (number of possible states that the distribution can take, also known as the support of the distribution). A Bayesian network is a graphical representation of such a probability distribution and in the unsimplified case above, a fully connected directed acyclic graph (DAG) with nodes representing the elements of the vector and the directed edges representing the dependence.</p>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/#conditional-independence-in-a-bayesian-network","title":"Conditional independence in a Bayesian network","text":"<p>One way to simplify the computation of the joint distribution is to assume conditional independence - equivalent to removing certain edges from the Bayesian network. The simplest example of this would be a Markov model where an element (or node in a DAG) is independent of every other (historical) element given the immediate previous one</p> \\[ p(x_{i} \\perp x_{i-2},\\dots,x_2,x_1 | x_{i-1}) \\] <p>and the chain rule factorisation simplifies to</p> \\[ p(x_1, x_2, \\dots, x_n) = p(x_n | x_{n-1}) \\dots p(x_3 | x_2) \\cdot p(x_2 | x_1) \\cdot p(x_1) \\] <p>A general Bayesian network would be one where every value is conditionally dependent on a few others (\\(\\ll n\\)) thereby simplifying the joint distribution to</p> \\[ p(x_1, x_2, \\dots, x_n) = \\prod_{i=1}^n p(x_i | \\hat{\\mathbf{x}_i}) \\] <p>where \\(\\hat{\\mathbf{x}_i}\\) denotes the subset of elements of \\(\\mathbf{x}\\) on which \\(x_i\\) is conditionally dependent.</p>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/#chain-rule-based-autoregressive-generators","title":"Chain rule based autoregressive generators","text":"<p>Another way to simplify the computation is to assume that there exists a computable function that can closely approximate the conditional probabilities. If we are dealing with discrete variables, then this function is a probability mass function (PMF), while if we are dealing with continuous variables then it is the probability density function (PDF). The structure remains the same and for the case of a fully connected network (chain rule factorisation) the implementation can be represented by the figure below where the \\(N_i\\) blocks represent the individual functional approximations of the conditional probabilities with each model (increasing \\(i\\)) being progressively more complex than the previous one.</p> <pre><code>graph TD\n    %% Input Nodes\n    x0((x.)) --&gt; N1\n    x1((x\u2081)) --&gt; N2\n    x1((x\u2081)) --&gt; N3\n    x1((x\u2081)) --&gt; N4\n    x2((x\u2082)) --&gt; N3\n    x2((x\u2082)) --&gt; N4\n    x3((x\u2083)) --&gt; N4\n\n    %% Process Blocks\n    N1[N\u2081] --&gt; y1((\"p(x\u2081)\"))\n    N2[N\u2082] --&gt; y2((\"p(x\u2082|x\u2081)\"))\n    N3[N\u2083] --&gt; y3((\"p(x\u2083|x\u2082,x\u2081)\"))\n    N4[N\u2084] --&gt; y4((\"p(x\u2084|x\u2083,x\u2082,x\u2081)\"))\n\n    %% Additional Inputs\n    x4((x\u2084))</code></pre> <p>Fully visible sigmoid belief networks (FVSBN) use logistic regression for each of the individual models. Results however are not good with this technique for image generation, since logistic regression is not complex enough to capture relationships in the images.</p> <p>Using neural networks instead, works better as is the case with neural autoregressive distribution estimator (NADE) which uses single layer neural networks for each of the models. Unlike logistic regression, a neural network can introduce non-linearities and is therefore much more flexible in learning features and the results are much more impressive. Parameter sharing (tying weights) reduces parameters, speeds up training and generation. If we use a similar architecture to model a general Bayesian network with conditional independence simplifications it reduces to</p> \\[ p(x_1, x_2, \\dots, x_n) = \\prod_{i=1}^n p_{neural}(x_i | \\hat{\\mathbf{x}_i}) \\] <p>where \\(\\hat{\\mathbf{x}_i}\\) are the nodes of the DAG on which \\(x_i\\) is conditionally dependent. Additionally this Bayesian network needs to satisfy the \"Markov\" ordering constraints imposed by the chain rule factorisation (so that generation is possible), which means</p> \\[ \\hat{\\mathbf{x}_i} \\subset \\{x_1, x_2, \\dots x_j\\} \\implies j &lt; i \\] Universal Approximation Theorem <p>A feedforward neural network with at least one hidden layer and a sufficiently large number of neurons can approximate any continuous function to any desired degree of accuracy, provided the network uses a non-linear activation function (like a sigmoid or ReLU)</p> <p>Generative models using the chain rule factorisation however require as many neural networks as there are input dimensions - each modelling a single conditional probability.</p>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/#generating-from-the-autoregressive-model","title":"Generating from the autoregressive model","text":"<p>Generating from the chain rule based autoregressive model has a similar architecture to the one used for training.</p> <ul> <li>\\(x_1\\) is sampled from the marginal prior distribution \\(p(x_1)\\).</li> <li>This is input to the first neural network \\(N_2\\) to obtain \\(p(x_2|x_1)\\) and \\(x_2\\) is sampled from this distribution.</li> <li>This process is repeated sequentially for all \\(x_{i \\le n}\\) to obtain the complete generation.</li> </ul> <p>As is obvious from the steps above, the generative process from an autoregressive model is sequential with each \\(x_i\\) from the generated vector, generated sequentially from the previously generated values.</p>"},{"location":"Generative%20AI/2.%20Autoregressive%20models/#autoencoders-as-autoregressive-generators","title":"Autoencoders as autoregressive generators","text":"<p>Autoencoders are generally used to obtain a compressed representation of the inputs. Their structure being that of a generalised Bayesian network can be used to modify them to function as an autoregressive model under certain constraints. The conditional probabilities are</p> \\[ p(x_1, x_2, \\dots, x_n) = \\prod_{i=1}^n p_{neural}(x_i | \\hat{\\mathbf{x}_i}) \\] <p>where \\(\\hat{\\mathbf{x}_i}\\) are the nodes of the DAG on which \\(x_i\\) is conditionally dependent.</p> <pre><code>graph TD\n    %% Input Nodes\n    x1((x\u2081)) --&gt; N\n    x2((x\u2082)) --&gt; N\n    x3((x\u2083)) --&gt; N\n    x4((x\u2084)) --&gt; N\n\n    %% Process Blocks\n    N[Autoencoder] --&gt; y4((\"p(x\u1d62|x\u0302\u1d62)\"))</code></pre> <p>A vanilla autoencoder however, is not a generative model. Since the DAG modelled by the neural network does not have any inherent ordering, it does not provide us with a meaningful way to generate samples from the model because the model is non-causal with respect to the input sequence.</p> <p>If we are able to constrain the DAG so as to force some kind of sequential ordering on the dependencies similar to what we achieve using chain rule factorisation, we can use the autoencoder as an autoregressive generative model. This is precisely what is done in a masked autoencoder for distributed estimation (MADE) where masks are used to disallow certain paths in the DAG so as to follow an ordered dependency sequence. The advantage of such a model over the chain rule factorisation is that a single neural network (deep) can model the joint probability distribution.</p> <p>The generative process is however exactly the same as before and is sequential and time consuming.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2024/10/02/regression/","title":"Linear and logistic regression","text":"<p>Linear and logistic regression are the simplest models used in supervised learning tasks like modelling a dependent variable and classification.</p>","tags":["ai","ml"]},{"location":"blog/2024/10/02/regression/#modelling-a-dependent-variable","title":"Modelling a dependent variable","text":"<p>Linear regression is used to model a dependent variable by fitting a straight line as close as possible to the data points</p> \\[ y = w_0 + w_1 x_1 + w_2 x_2 + \\dots + w_n x_n \\] <p>by minimising the mean square error </p> \\[ MSE = \\frac{1}{n}\\sum_{\u200bi=1}^{n}\u200b(y_i\u200b \u2212 \\hat{y}_i\u200b)^2 \\]","tags":["ai","ml"]},{"location":"blog/2024/10/02/regression/#linear-binary-classification","title":"Linear binary classification","text":"<p>Linear regression can also be used for binary classification, however in classification problems the goal is to find the probability of a data point belonging to a certain class. Linear regression being unbounded is unsuitable for this purpose. Logistic regression simply adds a non-linear sigmoid function to the output of a linear regression (the logit) to bound the values to legitimate probabilities.</p> \\[ p = \\sigma(z) = \\frac{1}{1 + e^{\u2212z}\u200b} \\] <p>Since we are trying to model probability distributions here, the loss we try to minimise here is the cross-entropy between the sample distribution and the predicted distribution</p> \\[ Loss  = -\\frac{1}{N}\\sum_{i=1}^{N}\u200b[y_i\u200b\\log(p_i\u200b)+(1\u2212y_i\u200b)\\log(1\u2212p_i\u200b)] \\] <p>Minimising the cross-entropy is equivalent to maximising log likelihood of the training samples (MLE).</p>","tags":["ai","ml"]},{"location":"blog/2024/10/02/regression/#categorical-classification","title":"Categorical classification","text":"<p>Multinomial logistic regression is an extension of logistic regression to cover categorical classifications. For \\(K\\) classes the model computes the linear decision boundary (logit) for each class </p> \\[ z_k \u200b= w_{0,k}\u200b+w_{1,k\u200b}x_1\u200b+w_{2,k}\u200bx_2\u200b+\\dots+w_{n,k}\u200bx_n\u200b \\] <p>and then converts these into probabilities using the softmax function</p> \\[ P(y=k\u2223x)=\\frac{e^{z_k}}{\\sum_{j=1}^{K}\u200be^{z_j}}\u200b\u200b\u200b \\] <p>Multinomial logistic regression minimises the cross-entropy loss, which generalises the log-loss for multiple classes. </p>","tags":["ai","ml"]},{"location":"blog/2024/10/02/regression/#regularisation","title":"Regularisation","text":"<p>The main aim of regularisation is to prevent overfitting and improve generalisation. In logistic regression models there are several levels of regularisation</p> <ol> <li>L1 regularisation (Lasso) for feature selection (driving certain coefficients to zero) of the most important features encouraging sparsity of the model</li> <li>L2 regularisation (Ridge) prevents overfitting by constraining the weights (shrinking the coefficients) thereby reducing the variance of the model</li> </ol>","tags":["ai","ml"]},{"location":"blog/2024/10/02/regression/#limitations","title":"Limitations","text":"<p>There is a limited subset of problems that lend itself to a ** linear decision boundary**. For example the simple XOR problem cannot be solved by logistic regression.</p> <p>Another limitation is the sensitivity to feature scaling. Normalisation techniques can help here, but at the end of the day we are tampering with the input data thereby introducing inefficiencies.</p>","tags":["ai","ml"]},{"location":"blog/2024/10/03/bv/","title":"Bias variance tradeoff","text":"<p>The bias-variance tradeoff explains the relationship between a model's complexity and predictive capability vs it's generalisation capabilities. It provides us a framework to balance overfitting and underfitting.</p> <p>Bias is a measure of underfitting and refers to the error introduced by an underfit model in explaining a complex real-world phenomenon. </p> <p>Variance on the other hand is a measure of overfitting and refers to the sensitivity of the model to changes in the training data.</p> <p>The tradeoff refers to the objective of balancing the model in such a way that it is sufficiently complex to learn the underlying features well without memorising the training data. </p> <p>Overfitting can be overcome in deep neural networks by L2 regularisation, early stopping and using sufficient and diverse training data. Transfer learning, since it is pre-trained on large diverse datasets is more immune to overfitting on noise and minor feature patterns in the training data. </p> <p>Very large and deep neural networks although having a tremendous propensity to overfit, ironically avoid overfitting when trained with large and diverse training data with proper regularisation in what is called the over parameterisation paradox.</p>","tags":["ai","ml"]},{"location":"blog/2024/10/06/gnn/","title":"Gradient boosting","text":"<p>Gradient boosting is an ensemble technique that creates strong learning models by iteratively adding the predictions from weak learners. </p> <p>In the case of decision trees these weak learner are typically shallow decision trees and each new iteration attempts to add trees that correct the errors made by the previous combined ensemble guided by the gradient of a loss function.</p> <p>Another way to look at these iterations are as additive models progressively developing an increasingly accurate composite model by adding simpler models in a greedy manner.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#methodology","title":"Methodology","text":"<p>Lets take a concrete example to understand gradient boosting. Lets say we have a n-sample training set with 5 factors / inputs \\((x_1, x_2, x_3, x_4, x_5)\\) and we are solving a 3-class \\((a, b, c)\\) classification problem.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#initial-weak-tree","title":"Initial weak tree","text":"<p>Gradient boosting methods start with an initial weak model such as a binary split using a favourable feature or even a uniform probability distribution among all the classes - in our example case this would mean that we initially assign \\((p_a, p_b, p_c) = (1/3, 1/3, 1/3)\\) for all training samples.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#loss-function","title":"Loss Function","text":"<p>We then use a loss function to measure the discrepancy between predicted and actual values. For classification problems, a common loss function is log loss or cross-entropy loss. For a single training example with true labels \\((y_a, y_b, y_c)\\) and predicted probabilities \\((p_a, p_b, p_c)\\) the multi-class cross-entropy loss is given by</p> \\[ \\text{Loss} = -[y_a \\log(p_a) + y_b \\log(p_b) + y_c \\log(p_c)] \\]","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#gradient-calculation","title":"Gradient calculation","text":"<p>The gradient of the loss function with respect to the predicted probabilities is then computed. For the cross-entropy loss above, the gradient of the loss reduces to the residual for a particular class</p> \\[ {\\partial L}_j = p_j - y_j \\]","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#next-tree-training","title":"Next tree training","text":"<p>For multi-class classification, gradient boosting typically builds one tree per class per iteration. Each tree is trained on the corresponding set of residuals (gradients) for that class, using the original input features. </p> <p>In our 3-class example, we would build three trees in parallel (or sequentially), one for each class\u2019s residuals. Each tree tries to best fit the residuals for that specific class dimension. Effectively what we are training these new trees to do is to predict the negative residuals so that when added to the original ensembles outputs, the final predictions we get come closer to the true labels. </p> <p>The tree-building algorithm (e.g., greedy splitting) attempts to find splits on input features \\((x_1, x_2, x_3, x_4, x_5)\\) that lead to more homogeneous residual values within leaves. This means that leaves represent regions of the input space where the model needs similar corrections for that particular class\u2019s predictions.</p> <p>After these three new trees are built, they are added to the current ensemble. The model updates the predictions for each class by adding the outputs of the corresponding tree (multiplied by the learning rate) to the previous scores to obtain refined predictions for the individual classes.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/06/gnn/#subsequent-iterations","title":"Subsequent iterations","text":"<p>The process of computing the loss function, it's gradient and generating 3 new trees continues until a desired number of iterations is reached or any of the other stopping criteria are met. Typical stopping criteria may include predefined loss threshold or non improvement of a validation score based on a validation set (taken out of the training set).</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2016/11/09/broken_trips/","title":"Patching broken trip information in GPS traces","text":"<p>GPS traces have gaps in transmission. These often occur, but are not confined to the beginning of a trip.</p> <p>They can also occur on highways or tunnels or parking lots. In our traces we have found that breaks in routes of more than a km in length occur in about 5% of the trips. The length of these broken routes could be as large as 10 km. In addition we see completely missing trip ends (a new trip does not start at the location that the previous trip ended). Our objective is to patch the broken routes and missing ends with the most probable actual route.</p>","tags":["gis"]},{"location":"blog/2016/11/09/broken_trips/#architecture","title":"Architecture","text":"","tags":["gis"]},{"location":"blog/2016/11/09/broken_trips/#extracting-broken-sections","title":"Extracting broken sections","text":"<p>Firstly we need to define what constitues a break in a trip which needs patching. This could be as small as 250m for devices that support that level of accuracy. Based on this then broken sections can be identified.</p>","tags":["gis"]},{"location":"blog/2016/11/09/broken_trips/#obtaining-reference-routes","title":"Obtaining reference routes","text":"<p>The reference routes are obtained from historic trips that the user has made across the broken section. There could be multiple routes which cover the broken section.</p> <p>Reference route segments are pulled from the historic route data such that:</p> <ul> <li>Both the ends of broken section are within a certain distance (20m) of the reference route. This distance of 20m works well for data from our car users. However for more stringent checks (e.g. frequent passings through railway stations, parking lots etc) a more flexible value or repetitive checks with greater radii is probably needed.</li> <li>there is at least one GPS point between the two in the reference route (i.e. the reference route does not have this section missing). </li> </ul>","tags":["gis"]},{"location":"blog/2016/11/09/broken_trips/#assigning-weights-to-reference-routes","title":"Assigning weights to reference routes","text":"<p>The reference routes thus obtained are then reduced into unique sets by comparing them with each other for similarity. Routes are aggregated based on:</p> <ul> <li>mean distance between routes being less than 20m</li> <li>Hausdorff distance being less than 100m</li> </ul> <p>The reference sets are assigned weights (size of the set) based on the number of times the user used that particular route historically. The best candidate reference route is the one with the highest weight.</p>","tags":["gis"]},{"location":"blog/2016/11/09/broken_trips/#an-example-patch","title":"An example patch","text":"<p>The original broken trip with the break marked:</p> <p></p> <p>The patched trip:</p> <p></p>","tags":["gis"]},{"location":"blog/2016/10/10/clean_trips/","title":"Cleaning GPS traces for accurate routes and distances","text":"<p>Inaccuracies and errors in GPS data are common and pose a unique challenge to trip and route processing.</p> <p>Unlike most communication technologies which use a terrestrial infrastructure, GPS requires the use of satellites to pinpoint locations. This introduces a unique set of challenges in obtaining a continuous and accurate stream of location traces.</p>","tags":["gis"]},{"location":"blog/2016/10/10/clean_trips/#invalid-gps-traces","title":"Invalid GPS traces","text":"<p>There are several factors that contribute to inaccuracies in the GPS data. Impediments between the GPS device and the satellite in the form of tall buildings, tunnels or underground parking lots in urban areas or tall trees in the countryside are the most common causes. The traces in such cases could either be completely missing or could point to a wrong location due to multipath effects. Adverse atmospheric effects could also lead to invalid GPS traces. Most of these inaccuracies are non-systematic and simple signal processing techniques are effective in eliminating them. </p>","tags":["gis"]},{"location":"blog/2016/10/10/clean_trips/#low-pass-filter-based-on-acceleration","title":"Low pass filter based on acceleration","text":"<p>Since the invalid GPS traces are random, the distance traversed between the invalid GPS trace and adjacent valid traces is often large for the time duration. Hence the speed of the vehicle required to traverse this distance is very high. A filter on speed alone though effective, does not eliminate all invalid traces according to our findings. What we discover is that since the direction of these traces is also random, the angle incident between the valid and invalid traces is almost always acute. Hence the acceleration required to traverse the path in the specified time intervals are always extremely high compared to valid GPS traces.</p> <p></p> <p>Our results suggest that an acceleration based filter is very effective in eliminating almost all invalid GPS traces and at the same time has negligible false negatives - ie genuine GPS traces with acute angles or high speeds as in U-turns and motorways respectively remain untouched.</p>","tags":["gis"]},{"location":"blog/2016/10/10/clean_trips/#out-of-sequence-traces-clock-errors","title":"Out of sequence traces (Clock Errors)","text":"<p>Clock errors are a very problematic cause of invalid GPS traces. They introduces out of sequence GPS traces resulting in routes that go back and forth between locations and consequently incorrect distance measurements. They also can take the form of small glitches in the traced route. The raw route and the result of passing the route through an acceleration filter are shown below.</p> <p></p> <p>A real-life example is this particularly bad GPS trace received from one of our earliest prototypes.</p> <p></p>","tags":["gis"]},{"location":"blog/2016/10/10/clean_trips/#static-gps-traces","title":"Static GPS traces","text":"<p>Some GPS devices are programmed to send traces at periodic intervals even when the vehicle is stationary. Sometimes these traces are all over the place because the device is not able to lock-on to a satellite. There incorrect GPS traces can also be filtered out using the acceleration filter.</p> <p></p>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/","title":"Geographic distances","text":"<p>Geographic distances are those on spherical geometry, but not quite.</p> <p>When dealing with IoT in the connected car space, most tasks require comparison between routes or segments of the journey ([lat, long] pair strings) for similarity. We also need accurate distance measurements to calculate higer order functions like speed and acceleration. There are two primary distances we need to compute when making sense of GPS traces - all others are a function of these two.</p> <ul> <li>The first is the distance between two points and </li> <li>The second one is the minimum distance between a point and a line segment.</li> </ul>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#geographic-distance-approximations","title":"Geographic Distance Approximations","text":"<p>The methods described below are summarized from Movable Type Scripts.</p>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#equirectangular-projection","title":"Equirectangular projection","text":"<p>In this method the geographic coordinates on the surface of the earth are projected onto an equirectangular plane and then the distances are measured as if on a plane surface. For distances of even a few hundred km this gives negligible errors compared to the more complicated haversine and should serve our purpose very well. Where this method fails is when we need to compute variables that are a function of more than one distance measure like the angle between segments. In this case the tiny errors magnify and make the resultant computation inaccurate and sometimes absurd.</p> <pre><code>def equirectangular(pointA, pointB):\n    \"\"\"\n    Find the distance between two points on earth.\n    \"\"\"\n    R = 6371000\n    latA = radians(pointA[1])\n    lngA = radians(pointA[0])\n    latB = radians(pointB[1])\n    lngB = radians(pointB[0])\n    x = (lngA - lngB)*cos((latA + latB)/2)\n    y = (latA - latB)\n    distance = R * sqrt(x*x + y*y)\n    return distance\n</code></pre>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#great-circle-distance-or-haversine","title":"Great circle distance or haversine","text":"<p>The most popular approximation for geographic distances is to assume the earth to be a regular sphere and calculate distance using the haversine formula. We have felt the need to use this only in measuremnts of angles where we use the bearing of a segment computed using the haversine formula.</p>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#other-functions-based-on-geographic-distance","title":"Other functions based on geographic distance","text":"","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#minimum-distance-between-a-point-and-a-line","title":"Minimum distance between a point and a line","text":"<p>Since we are projecting onto a plane, we use the regular 2D method of determining the height of the triangle with base as the line. We use Heron's formula to get the area and then the height - which is the minimum distance. Before doing this we check whether the projection of the point lies on the line segment or outside it. If outside we calculate the minimum distance as the minimum distance to the end points of the line.</p> <pre><code>def check_projection(point, start, end):\n    \"\"\"\n    Check whether the perpendicular projection of the point falls \n    on the line segment defined by start and end coordinates. \n    \"\"\"\n    dx = end[0] - start[0]\n    dy = end[1] - start[1]\n    dot = (point[0] - start[0])*dx + (point[1] - start[1])*dy\n    return (0 &lt; dot and dot &lt; (dx*dx + dy*dy))\n\ndef point2segment(point, segment):\n    \"\"\"\n    Find the minimum distance between a point and line segment\n    \"\"\"\n    start = segment[0]\n    end = segment[1]\n    b = equirectangular(start, end)\n    a = equirectangular(start, point)\n    c = equirectangular(end, point)\n    if not check_projection(point, start, end):\n        min_distance = min(a, c)\n    elif b == 0:\n        min_distance = a\n    else:\n        s = (a+b+c)/2\n        A = sqrt(max((s*(s-a)*(s-b)*(s-c)), 0))\n        min_distance = 2*A/b\n    return min_distance\n</code></pre>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#hausdorff-distance","title":"Hausdorff Distance","text":"<p>Hausdorff distance between the target route and a reference route is the distance of the point on the target route that is farthest away from the reference route.</p>","tags":["gis"]},{"location":"blog/2016/09/18/gis_distance/#angle-between-two-line-segments","title":"Angle between two line segments","text":"<pre><code>def angle_degrees(prev_pt, point, next_pt):\n    \"\"\"\n    Find angle between two segments (three points)\n    \"\"\"\n    latA = radians(prev_pt[1])\n    lngA = radians(prev_pt[0])\n    latB = radians(point[1])\n    lngB = radians(point[0])\n    latC = radians(next_pt[1])\n    lngC = radians(next_pt[0])\n\n    y1 = cos(latB)*sin(lngB-lngA)\n    x1 = cos(latA)*sin(latB) - sin(latA)*cos(latB)*cos(lngB-lngA)\n    bearing_1 = (degrees(atan2(y1, x1)) + 360) % 360\n\n    y2 = cos(latC)*sin(lngC-lngB)\n    x2 = cos(latB)*sin(latC) - sin(latB)*cos(latC)*cos(lngC-lngB)\n    bearing_2 = (degrees(atan2(y2, x2)) + 360) % 360\n\n    if (bearing_1 == 0) or (bearing_2 == 0):\n        angle = 0\n    else:\n        angle = min((bearing_1-bearing_2+360)%360, (brng2-bearing_1+360)%360)\n    return angle\n</code></pre>","tags":["gis"]},{"location":"blog/2024/11/04/sgd/","title":"Stochastic gradient descent","text":"<p>Stochastic gradient descent is an iterative optimisation technique used to optimise model parameters of a neural network model during training by minimising the error function. </p>","tags":["ai","ml","neural-net"]},{"location":"blog/2024/11/04/sgd/#neural-network-training","title":"Neural network training","text":"<p>A training cycle for a neural network involves the following steps:</p> <ol> <li>Forward pass for a single training sample to compute the loss vector</li> <li>Accumulate losses over a set of samples and compute the sum / mean of the errors</li> <li>Back propagation to compute the gradient of the aggregated loss with respect to all the neural network parameters (weights and biases)</li> <li>Update the parameters using the computed gradients throttled by a learning rate</li> </ol>","tags":["ai","ml","neural-net"]},{"location":"blog/2024/11/04/sgd/#gradient-descent","title":"Gradient descent","text":"<p>In the early machine learning problems (eg Titanic problem in Kaggle), with limited training data, the whole training data could be passed through the neural network during training due to limited memory requirements. The standard method of gradient descent then was to use the complete batch of training data in a single training cycle. This would then be repeated over multiple passes of the entire batch (called epochs).</p>","tags":["ai","ml","neural-net"]},{"location":"blog/2024/11/04/sgd/#stochastic-gradient-descent-sgd","title":"Stochastic gradient descent (SGD)","text":"<p>As training data became massive with the advent of deep learning and large neural networks, storing the entire batch in memory for gradient computation became impossible. Standard gradient descent updated the parameters too infrequently slowing down learning and convergence. With the advent of GPUs, more frequent computations of the gradients became practical. </p> <p>SGD uses stochastic mini batches (or even single samples) per training cycle, thereby leveraging the computational advancements to make the training process more scalable for deep learning. A collateral benefit of SGD was that it was found to perform an implicit regularisation due to the slight variability of the mini batches. This \"noise\" helps the model avoid overfitting and improves generalisation.</p> <p>SGD has now become the de-facto optimisation method in deep learning.</p>","tags":["ai","ml","neural-net"]},{"location":"blog/2024/10/08/gnn/","title":"Support vector machines","text":"<p>Support vector machines are the most popular application of kernel methods which are a class of algorithms used to simplify non-linear classification problems by projecting the data onto higher dimensions so as to be able to apply linear regressions.</p>","tags":["classification","ml"]},{"location":"blog/2024/10/08/gnn/#feature-space-transformation","title":"Feature space transformation","text":"<p>Kernel methods use the concept of feature space transformation to project the input data onto one or more higher dimensions. The non-linear classification problem in the input vector space consequently gets modified to a linear classification problem in the higher dimensional space and one can find a hyperplane to classify the data.</p>","tags":["classification","ml"]},{"location":"blog/2024/10/08/gnn/#kernel-trick","title":"Kernel trick","text":"<p>Normally when one does a feature space transformation, it requires computing the transformed space for the input data sets and then computing the cosine distance (dot product) of the samples in the the transformed space. The kernel trick uses a kernel function which directly gives this dot product without having to transform the data into the higher dimensional space.</p>","tags":["classification","ml"]},{"location":"blog/2024/10/08/gnn/#kernel-functions","title":"Kernel functions","text":"<p>The most commonly used kernel functions are:  Polynomial Kernel of different degrees</p> <p>$$ K(x,y)=(x\u22c5y+c)^d $$ where d is the degree of the the polynomial.  Radial basis function kernel</p> \\[ K(x,y)=e^{(\u2212\u03b3\u2225x\u2212y\u2225^2)} \\] <p>is the default choice for non-linear problems due to its flexibility and general applicability.</p>","tags":["classification","ml"]},{"location":"blog/2024/10/08/gnn/#support-vector-classifier","title":"Support vector classifier","text":"<p>Support Vector Machines (SVMs) aim to classify data points by finding the optimal hyperplane that separates two classes of data with the maximum margin. A hyperplane in \\(\\mathbb{R}^n\\) is defined as:</p> \\[ f(\\mathbf{x}) = \\mathbf{w} \\cdot \\mathbf{x} + b = 0 \\] <p>where \\(\\mathbf{w}\\) is the normal vector to the hyperplane and \\(b\\) is the bias term (intercept) The hyperplane separates the two classes:</p> <ul> <li>If \\(f(\\mathbf{x}) &gt; 0: \\mathbf{x}\\) belongs to Class \\(+1\\)</li> <li>If \\(f(\\mathbf{x}) &lt; 0: \\mathbf{x}\\) belongs to Class \\(\u22121\\)</li> </ul> <p>Initially, the hyperplane can be randomly assigned or set using a heuristic method (e.g., least-squares approximation). The margin is defined as the distance between the hyperplane and the closest points from either class (called support vectors). The goal of the SVM is to find the hyperplane that maximises the margin between the two classes.</p> <p>Soft Margin SVM allow some errors where perfect separation may not be possible such as in the case of most real-world data.</p>","tags":["classification","ml"]},{"location":"blog/2024/10/08/gnn/#comparison-of-classification-methods","title":"Comparison of classification methods","text":"Aspect SVMs Gradient Boosting Neural Networks Dataset Size Small to Medium Medium to Large Large Scalability Poor Good Excellent Data Type High-dimensional, Sparse Tabular Unstructured (images, text) Interpretability Moderate High Low Ease of Tuning Moderate Moderate Complex Computational Cost Moderate Moderate High Performance on Non-Linear Data Excellent (with kernels) Excellent Excellent Output Class Labels or Margins Probabilities Probabilities Domain Examples Text, Bioinformatics Finance, Healthcare Images, Text, Complex Patterns","tags":["classification","ml"]},{"location":"blog/2024/10/05/trees/","title":"Decision trees and forests","text":"<p>Decision trees are hierarchical rule based models that provided an advancement over logistic regression in classification problems - for example in solving the XOR problem.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/05/trees/#decision-trees","title":"Decision trees","text":"<p>In many problems like the Titanic competition on Kaggle, it is observed that a single binary decision is much more accurate in predicting outcomes than more complicated methods like regressions. In the Titanic case for instance whether a person survives or not is rather well predicted by whether they were male or female or which class their ticket belonged to. Now if we build a sequence of decision as a decision tree, the leaf nodes would give us the probability of the outcome for an unknown input by simply traversing the tree.</p> <p>The advantages of decision trees are that </p> <ul> <li>They require no transformation of the input variables because they do not combine the variables in building or traversing the tree. </li> <li>They can handle categorical variable without encoding</li> <li>Since this is a multilayer function with a non-linear step function as activation, it ultimately results in a non-linear decision boundary and can handle XOR like problems. </li> <li>Since the decisions are based on input features, the predictions are easily interpretable compared to neural networks or logistic regression</li> </ul> <p>The feature to be used as the conditional at every node in partitioning the data (order of decisions) is determined based on criteria like the Gini impurity (the probability of misclassifying a randomly chosen sample) or information gain (the reduction in entropy after a dataset is split on a feature).</p> <p>A comprehensive decision tree exactly mimics the training data with each leaf node being a pure subset and is the very definition of overfitted. To avoid this the tree is pruned after a certain depth using a stopping condition e.g., maximum tree depth, minimum samples per leaf, or pure subsets. However single decision trees are still prone to overfitting, but ironically they also suffer from high sensitivity to changes in training data, thereby leading to high variance.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/2024/10/05/trees/#bagging-random-forests","title":"Bagging - Random forests","text":"<p>Bagging is an ensemble technique to reduce variability and overfitting by creating different trees and taking a majority vote of the predictions. </p> <p>In random forests the different trees are trained using bootstrapped samples (repeatedly sampling from the training set with replacement). Additionally each tree also uses a random subset of features at each split. These randomisations and sampling methods further de-correlate the trees, typically leading to better performance.</p>","tags":["ml","classification","ensemble"]},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/archive/2016/","title":"2016","text":""},{"location":"blog/category/learning/","title":"learning","text":""},{"location":"blog/category/neural-networks/","title":"neural networks","text":""},{"location":"blog/category/gis/","title":"gis","text":""}]}